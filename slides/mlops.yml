title: |
  Asynchronous Architecture Patterns To Scale ML and Other High Latency Workloads on Kubernetes

#chat: "[Slack](https://dockercommunity.slack.com/messages/C7GKACWDV)"
#chat: "[Gitter](https://gitter.im/jpetazzo/workshop-yyyymmdd-city)"
chat: "In person!"

gitrepo: github.com/jpetazzo/container.training

slides: https://FIXME.container.training/

#slidenumberprefix: "#SomeHashTag &mdash; "

exclude:
- self-paced

content:
- shared/title.md
- logistics.md
- shared/about-slides.md
#- shared/chat-room-im.md
#- shared/chat-room-slack.md
#- shared/chat-room-zoom-meeting.md
#- shared/chat-room-zoom-webinar.md
- k8s/prereqs-advanced.md
# Note: if we work on this later, we should refactor it
# to follow the same pattern as the other classes
# (i.e. use the k8s/labs-*.md files)
- k8s/handson-mlops.md
- shared/connecting.md
- k8s/mlops-headsup.md
- shared/toc.md
-
  - k8s/ollama-intro.md
  - k8s/ollama-metrics.md
  - k8s/queue-architecture.md
  - k8s/bento-intro.md
-
  - k8s/resource-limits.md
  - k8s/cluster-autoscaler.md
  - k8s/ollama-reqlim.md
  - k8s/bento-hpa.md
  - k8s/bento-rmq.md
  - k8s/bento-cnpg.md
  - k8s/helmfile.md
  - shared/thankyou.md
  - shared/contact.md
